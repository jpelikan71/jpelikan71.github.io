---
title: 'Phenomenological Models and Machine Learning '
date: 2020-05-11
permalink: /posts/2020/05/blog-post-1/
tags:
  - complex systems
  - phenomenological modelling
---

Model creating process traditionally used to study the properties and to make predictions of behavior (dynamics) of various systems, both natural and artificial. Model is built on the basis of a certain set of measurements of system individual characteristics. Based on any theoretical approaches applicable to this system, one can try to obtain a formal description of the structure and (or) dynamics of this system, for example, as a set of mathematical equations describing the relationships between the parameters of the system under study. Such a model may be used for description of rather complex systems and phenomena (for example, temperature distribution over the surface of an object; exchange and transformation reactions of substances in a living cell; mechanical deformations when processing a part, etc.).
The classical approach of model creation (often called “mechanistic”) consists in forming a system of equations (differential, discrete-difference) that relate the system parameters; and for modeling dynamics, they also describe the dependence of these parameters on time. The basis of such a system of equations are known laws that can be applied to the description of the system (for example, the laws of thermodynamics, hydrodynamics, electrodynamics, chemical-kinetic reactions, mechanics, etc.).
If the laws of change and the relationship of parameters are unknown, they can be derived from a set of empirical data. During a series of measurements of system parameters under various conditions, one can obtain a set of tabular data and then find a functional dependence that most closely approximates the relationship between the parameter values.
This type of model has a certain drawback: the possibility of random changes in parameters and random effects on the system is not taken into account. The randomness factor may emerge be due to the following reasons:
- random external influences and noises;
 - measurement errors, noise in measuring systems;
- the random nature of changes in system parameters, for example, in the initial positions of the interacting elements of the system.
The randomness factor may be involved in system model by using probability distributions for parameters with random nature influences. Depending on the importance of the system parameters, randomly varying values can either be filtered out or evaluated further in the framework of a certain probabilistic model.
The generated mechanistic model of the system can be implemented in the form of numerical calculation algorithms for further computer calculations.
The described approach to creating a system model can be called "classic." The created model can be assessed for accuracy of matching with a real system by comparing model and actual data; also it may be determined within which parameters boundaries this model is most reliable.

The weakness of this modelling approach is increasingly noticeable in recent years. 

Total automation of system characteristics measurements in various fields (industry, finance, life sciences, social phenomena, media, nature studies, etc.), large amounts of digital measurements data creation, and the desire to obtain new qualitative conclusions on the basis of the available data arrays, it requires the creation of ever new models. The above “mechanistic” approach requires a large amount of analytical work for each individual task of model creation, which must be carried out by a whole group of researchers.

It is obvious that sooner or later the available resources (researchers with relevant education and specialization in the applied field; centers and laboratories; research funding opportunities, etc.)  will be exhausted, since the number of modelling tasks requiring study will be many orders of magnitude higher than these resources.

A more effective approach may be called the phenomenological modelling. Simplifying somewhat, it is possible to present its essence as the possibility of application of  some “universal modeling device” that implements the following principles:
- “Device” does not realize the real physical (chemical, biological, ...) dependencies that describe the properties and dynamics of the system;
- Its main property is the ability to infer a set of output values of state or system dynamics parameters,  which is as close as possible to values obtained empirically, having received some input parameters.
The computer implementation of the phenomenological model uses input and output data in the form of tabular (matrix) digital sets of values. 
A popular area of machine learning can also be considered a phenomenological modeling tool, perhaps the most effective today. The vast majority of machine learning models used today in research and software applications developing are neural networks of various architectures. Neural networks show strong possibilities in modeling very complex systems, such as images and video, audio, complex geometric shapes, relationships in natural language texts, etc.
It makes no sense to once again describe the classification and applied value of the developed machine learning algorithms, their advantages and disadvantages - all this stuff can be found in a huge variety of popular and scientific articles, lectures and courses. The most interesting are the following aspects of machine learning based phenomenological models of complex systems:


Headings are cool
======

You can have many headings
======

Aren't headings cool?
------
